{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9371cf89",
   "metadata": {},
   "source": [
    "# Loading Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67fdbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ChemQ3-MTP Model Loader Starting...\n",
      "\n",
      "📥 Downloading model files from gbyuvd/ChemMiniQ3-SAbRLo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a18349d7d0446f84917c4210e47e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c189ed4f66940818e58d607bedc85af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f2152923a04f2384b32d730261846b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FastChemTokenizerHF.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ba19ee388d46f2850a658d23ccfe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52185bad3b46433d8f00033966c56fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "__init__.py:   0%|          | 0.00/569 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30a9f81452142a78b3620de2af17134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcdb946ea6d46aea24b32e59634a3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_chemq3mtp.py:   0%|          | 0.00/876 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe7ffbaee954fba83c91fcd2a95bb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c4779d2281423d986a7a13f2a1fe7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "demo_usage.ipynb: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c0220f0f8d4581b3ee1982454718e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/39.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895fb0bf2e174f0789f2d706f112fb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rl_utils.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52bfac339a44f79b2c872b21b9c8adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/302 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4f238b0826450f99ed4391089a1b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_chemq3mtp.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63205aab91ed4ffba775da0bc6509c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trainer.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1132b6a87d0541b3b86018790f26beed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba711a1314694d14834a0303e63706ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "trainer_state.json:   0%|          | 0.00/798 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fcdc572f6546c6aeeb063418c6db67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8626db65cf47e1b5bc88c9bfa42946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model downloaded to: D:\\Work\\ChemMiniQ3-HoriFIE-main\\ChemMiniQ3-HoriFIE-main\\ChemMiniQ3-o\\Automodel\\chemq3_model\n",
      "📁 Downloaded files:\n",
      "   .gitattributes (1519 bytes)\n",
      "   config.json (1161 bytes)\n",
      "   configuration_chemq3mtp.py (876 bytes)\n",
      "   demo_usage.ipynb (15239 bytes)\n",
      "   FastChemTokenizerHF.py (28659 bytes)\n",
      "   generation_config.json (174 bytes)\n",
      "   model.safetensors (39437252 bytes)\n",
      "   modeling_chemq3mtp.py (18125 bytes)\n",
      "   README.md (8575 bytes)\n",
      "   rl_utils.py (20726 bytes)\n",
      "   tokenizer_config.json (302 bytes)\n",
      "   trainer.py (2417 bytes)\n",
      "   trainer_state.json (798 bytes)\n",
      "   training_args.bin (5368 bytes)\n",
      "   training_config.json (252 bytes)\n",
      "   vocab.json (21574 bytes)\n",
      "   __init__.py (569 bytes)\n",
      "\n",
      "🔧 Loading custom modules from D:\\Work\\ChemMiniQ3-HoriFIE-main\\ChemMiniQ3-HoriFIE-main\\ChemMiniQ3-o\\Automodel\\chemq3_model...\n",
      "   ✅ Loaded configuration_chemq3mtp.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Loaded modeling_chemq3mtp.py\n",
      "   ✅ Loaded FastChemTokenizerHF.py\n",
      "\n",
      "🔗 Registering model components...\n",
      "✅ Model components registered successfully\n",
      "\n",
      "🚀 Loading model...\n",
      "✅ Config loaded: ChemQ3MTPConfig\n",
      "✅ Model loaded: ChemQ3MTPForCausalLM\n",
      "✅ Tokenizer loaded: FastChemTokenizerSelfies\n",
      "\n",
      "🧪 Testing model...\n",
      "🖥️  Using device: cuda\n",
      "\n",
      "📊 Model Information:\n",
      "   Model class: ChemQ3MTPForCausalLM\n",
      "   Config class: ChemQ3MTPConfig\n",
      "   Tokenizer class: FastChemTokenizerSelfies\n",
      "   Model type: chemq3_mtp\n",
      "   Vocab size: 782\n",
      "\n",
      "🔤 Testing tokenization...\n",
      "   '[C][C][O]' -> [[0, 379, 379, 377, 1]]\n",
      "   '[C]' -> [[0, 379, 1]]\n",
      "   '[O]' -> [[0, 377, 1]]\n",
      "\n",
      "🎯 Testing generation...\n",
      "\n",
      "   Prompt: '[C]'\n",
      "      1: [C] [C] [Ring1] [Branch1] [N] [C] [=Branch1] [C] [=O] [C] [=Branch1] [C] [=O] [N] [Branch1] [#Branch1] [C] [C] [=C] [C] [=C] [C] [=C] [Ring1] [=Branch1] [Ring1] [=Branch1]\n",
      "      2: [C] [C] [=C] [Ring1] [Branch1] [C] [C] [Ring1] [=N] [C] [Branch1] [=Branch2] [C] [Branch2] [Ring1] [#Branch1] [Branch1] [C] [O] [C@@H1] [Ring1] [Ring1]\n",
      "      3: [C] [N] [C] [=N] [C] [Branch1] [C] [Cl] [Ring1] [Branch2] [C] [Ring1] [=Branch1] [=C] [Ring1] [#C]\n",
      "\n",
      "   Prompt: '[C][C]'\n",
      "      1: [C] [C] [=N] [Ring1] [Branch1] [C] [=C] [C] [=C] [Ring1] [=Branch1] [C] [C] [Ring1] [S] [C]\n",
      "      2: [C] [C] [Branch1] [C] [F] [F] [Branch1] [C] [F] [Branch1] [C] [F] [Branch1] [C] [F] [=C] [Ring1] [#Branch1] [=C] [Ring1] [P]\n",
      "      3: [C] [C] [Ring1] [C] [C@@H1] [Branch1] [P] [N] [C] [C] [N] [Ring1] [=Branch1] [Ring1] [S] [Ring1] [S] [C] [Ring2] [Ring1]\n",
      "\n",
      "🔬 Testing MTP functionality...\n",
      "   ✅ MTP training methods available\n",
      "   ✅ MTP generation methods available\n",
      "\n",
      "🎉 Model loading and testing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import huggingface_hub\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def download_and_setup_model(model_name=\"gbyuvd/ChemMiniQ3-SAbRLo\", local_dir=\"./chemq3_model\"):\n",
    "    \"\"\"Download model files and set up the custom modules\"\"\"\n",
    "    \n",
    "    print(f\"📥 Downloading model files from {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Download all files to a local directory\n",
    "        model_path = huggingface_hub.snapshot_download(\n",
    "            repo_id=model_name,\n",
    "            local_dir=local_dir,\n",
    "            local_files_only=False,\n",
    "            resume_download=True\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Model downloaded to: {model_path}\")\n",
    "        \n",
    "        # List downloaded files\n",
    "        print(\"📁 Downloaded files:\")\n",
    "        for file in Path(model_path).iterdir():\n",
    "            if file.is_file():\n",
    "                print(f\"   {file.name} ({file.stat().st_size} bytes)\")\n",
    "        \n",
    "        return Path(model_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Download failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_custom_modules(model_path):\n",
    "    \"\"\"Load all the custom modules required by the model\"\"\"\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    \n",
    "    # Add the model directory to Python path\n",
    "    if str(model_path) not in sys.path:\n",
    "        sys.path.insert(0, str(model_path))\n",
    "    \n",
    "    print(f\"🔧 Loading custom modules from {model_path}...\")\n",
    "    \n",
    "    # Required module files\n",
    "    required_files = {\n",
    "        'configuration_chemq3mtp.py': 'configuration_chemq3mtp',\n",
    "        'modeling_chemq3mtp.py': 'modeling_chemq3mtp', \n",
    "        'FastChemTokenizerHF.py': 'FastChemTokenizerHF'\n",
    "    }\n",
    "    \n",
    "    loaded_modules = {}\n",
    "    \n",
    "    # Load each required module\n",
    "    for filename, module_name in required_files.items():\n",
    "        file_path = model_path / filename\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            print(f\"❌ Required file not found: {filename}\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            \n",
    "            # Execute the module\n",
    "            spec.loader.exec_module(module)\n",
    "            loaded_modules[module_name] = module\n",
    "            \n",
    "            print(f\"   ✅ Loaded {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Failed to load {filename}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return loaded_modules\n",
    "\n",
    "def register_model_components(loaded_modules):\n",
    "    \"\"\"Register the model components with transformers\"\"\"\n",
    "    \n",
    "    print(\"🔗 Registering model components...\")\n",
    "    \n",
    "    try:\n",
    "        # Get the classes from loaded modules\n",
    "        ChemQ3MTPConfig = loaded_modules['configuration_chemq3mtp'].ChemQ3MTPConfig\n",
    "        ChemQ3MTPForCausalLM = loaded_modules['modeling_chemq3mtp'].ChemQ3MTPForCausalLM\n",
    "        FastChemTokenizerSelfies = loaded_modules['FastChemTokenizerHF'].FastChemTokenizerSelfies\n",
    "        \n",
    "        # Register with transformers\n",
    "        AutoConfig.register(\"chemq3_mtp\", ChemQ3MTPConfig)\n",
    "        AutoModelForCausalLM.register(ChemQ3MTPConfig, ChemQ3MTPForCausalLM)\n",
    "        AutoTokenizer.register(ChemQ3MTPConfig, FastChemTokenizerSelfies)\n",
    "        \n",
    "        print(\"✅ Model components registered successfully\")\n",
    "        \n",
    "        return ChemQ3MTPConfig, ChemQ3MTPForCausalLM, FastChemTokenizerSelfies\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Registration failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the model using the registered components\"\"\"\n",
    "    \n",
    "    print(\"🚀 Loading model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load config\n",
    "        config = AutoConfig.from_pretrained(str(model_path), trust_remote_code=False)\n",
    "        print(f\"✅ Config loaded: {config.__class__.__name__}\")\n",
    "        \n",
    "        # Load model\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            str(model_path),\n",
    "            config=config,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            trust_remote_code=False  # We've already registered everything\n",
    "        )\n",
    "        print(f\"✅ Model loaded: {model.__class__.__name__}\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(str(model_path), trust_remote_code=False)\n",
    "        print(f\"✅ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "        \n",
    "        return model, tokenizer, config\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model loading failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "def test_model(model, tokenizer, config):\n",
    "    \"\"\"Test the loaded model\"\"\"\n",
    "    \n",
    "    print(\"\\n🧪 Testing model...\")\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"🖥️  Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Model info\n",
    "    print(f\"\\n📊 Model Information:\")\n",
    "    print(f\"   Model class: {model.__class__.__name__}\")\n",
    "    print(f\"   Config class: {config.__class__.__name__}\")\n",
    "    print(f\"   Tokenizer class: {tokenizer.__class__.__name__}\")\n",
    "    print(f\"   Model type: {config.model_type}\")\n",
    "    print(f\"   Vocab size: {config.vocab_size}\")\n",
    "    \n",
    "    # Set pad token if needed\n",
    "    if not hasattr(tokenizer, 'pad_token') or tokenizer.pad_token is None:\n",
    "        if hasattr(tokenizer, 'eos_token'):\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            print(\"✅ Set pad_token to eos_token\")\n",
    "    \n",
    "    # Test tokenization\n",
    "    print(\"\\n🔤 Testing tokenization...\")\n",
    "    test_inputs = [\"[C][C][O]\", \"[C]\", \"[O]\"]\n",
    "    \n",
    "    for test_input in test_inputs:\n",
    "        try:\n",
    "            tokens = tokenizer(test_input, return_tensors=\"pt\")\n",
    "            print(f\"   '{test_input}' -> {tokens.input_ids.tolist()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Tokenization failed for '{test_input}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Test generation\n",
    "    print(\"\\n🎯 Testing generation...\")\n",
    "    test_prompts = [\"[C]\", \"[C][C]\"]\n",
    "    \n",
    "    for prompt in test_prompts:\n",
    "        try:\n",
    "            input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    input_ids,\n",
    "                    max_length=input_ids.shape[1] + 20,\n",
    "                    temperature=0.8,\n",
    "                    top_p=0.9,\n",
    "                    top_k=50,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=tokenizer.pad_token_id if hasattr(tokenizer, 'pad_token_id') else 0,\n",
    "                    num_return_sequences=3\n",
    "                )\n",
    "            \n",
    "            print(f\"\\n   Prompt: '{prompt}'\")\n",
    "            for i, output in enumerate(outputs):\n",
    "                generated = tokenizer.decode(output, skip_special_tokens=True)\n",
    "                print(f\"      {i+1}: {generated}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Generation failed for '{prompt}': {e}\")\n",
    "    \n",
    "    # Test MTP functionality if available\n",
    "    print(\"\\n🔬 Testing MTP functionality...\")\n",
    "    try:\n",
    "        if hasattr(model, 'set_mtp_training'):\n",
    "            print(\"   ✅ MTP training methods available\")\n",
    "            if hasattr(model, 'generate_with_logprobs'):\n",
    "                print(\"   ✅ MTP generation methods available\")\n",
    "        else:\n",
    "            print(\"   ℹ️  Standard model - no MTP methods detected\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  MTP test error: {e}\")\n",
    "\n",
    "def main():\n",
    "    print(\"🚀 ChemQ3-MTP Model Loader Starting...\\n\")\n",
    "    \n",
    "    model_name = \"gbyuvd/ChemMiniQ3-SAbRLo\"\n",
    "    local_dir = \"./chemq3_model\"\n",
    "    \n",
    "    # Step 1: Download model files\n",
    "    model_path = download_and_setup_model(model_name, local_dir)\n",
    "    if model_path is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Step 2: Load custom modules\n",
    "    loaded_modules = load_custom_modules(model_path)\n",
    "    if loaded_modules is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Step 3: Register components\n",
    "    config_class, model_class, tokenizer_class = register_model_components(loaded_modules)\n",
    "    if config_class is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Step 4: Load the model\n",
    "    model, tokenizer, config = load_model(model_path)\n",
    "    if model is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Step 5: Test the model\n",
    "    test_model(model, tokenizer, config)\n",
    "    \n",
    "    print(\"\\n🎉 Model loading and testing completed successfully!\")\n",
    "    \n",
    "    return model, tokenizer, config\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer, config = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ea169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C@H1] [/C] [N] [Branch1] [N] [C] [=C] [C] [=C] [Branch1] [C] [Cl] [C] [=C] [C] [=C] [O] [Ring1] [=Branch1] [Ring2] [Ring1] [Ring1] [Ring1] [O] [C] [Branch1] [N] [C] [C@@H1] [Ring1] [=Branch1] [C] [C] [Ring1] [Branch2] [N] [C] [=Branch1] [C] [=O] [C] [=C] [Ring2] [Ring1] [Ring2] [O] [C] [C] [Ring1] [Ring1] [Ring2] [N] [C] [C] [Ring1] [Branch1]\n"
     ]
    }
   ],
   "source": [
    "# Generate SELFIES\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "input_ids = tokenizer(\"<s>\", return_tensors=\"pt\").input_ids.to(device)\n",
    "gen = model.generate(input_ids, max_length=256, top_k=50, temperature=1, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(gen[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd4f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C@H1]/CN(C=CC=C(Cl)C=CC=C)O\n"
     ]
    }
   ],
   "source": [
    "# Manually convert it to SMILES\n",
    "import selfies as sf\n",
    "\n",
    "test = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
    "test = test.replace(' ', '')\n",
    "print(sf.decoder(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf273a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C12=CC1(OCC=CC=C)C2\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAXTklEQVR4nO3daXSU1f0H8N9kYQ0hIARQ2ZElkCEBhJRQMRA2ibZYgshhWj09J+BpGLvYDtZDJ7anxwn6YqyeatBWI1h6ksoSCyRltQmUJTTEhAhaYgCFLEAcsoeZuf8Xl4xjZpI8z2y/MP/v5x3P3LnPnTDfZ7nLMxohBAEAnxDuBgD8f4cQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIYTgt2PHjgsXLnC3oksIIQS//Px8rVb7+OOPW61W7ra4oRFCcLcBwL+io6Pr6uqIaNy4cUePHh03bhx3i74DZ0IIfq2trUQUGhpaVVWl1Wq3bdvWq849CCEEv/vuu4+Ijh49qtPpGhoaNmzYsGLFiq+//pq7XXchhBD8LBYLEU2fPv2DDz7IyckZNmxYQUHBjBkztm3bxt00ItwTQtCz2Wx9+vTRaDTt7e0hISFEVFNTs2HDhr179xJRamrqn//852HDhjG2EGdCCHK3bt2y2+1DhgyRCSSiESNG7NmzJycnZ8iQIbm5uTNmzJCB5IIQQpC7efMmddwWOktNTS0pKUlKSqqpqfnhD3+4Zs2a+vp6jgYihBDsbty4QURuLzjHjh17+PDhrKysgQMH5ubmxsfHHzlyJOANRAgh2HV1JpQ0Gk1aWlppaemCBQsuX76cnJy8YcOGpqamQLYQIYQg130IpYkTJx49etRkMoWHh2/btk2r1RYVFQWqgQghBLtuLkedhYWFGQyG4uLi+Pj4ysrKpKSkzZs3t7e3B6CFCCEEOSVnQofY2NhTp04ZjUYhRGZm5uzZs0tKSvzcQIQQgp2qEBJReHh4RkZGUVHR5MmTy8vL582bl5GRYbPZ/NdChBCCnNoQSgkJCefOnTMYDDab7eWXX16wYMHFixf900CEEIKdwntCV/379zeZTAUFBaNHjz558mR8fHxmZqbdbvd5CxFCCHKenQkdkpOTy8vL09LSWlpaNm/evGzZsqtXr/q0gQghBDsvQ0hEkZGRWVlZ+/btu//++w8dOuTzmd+YwA3BTAjRp08fm83W1tYWHh7uZW11dXUbN27ctWsXEa1YseLdd9+9//77vW8kzoQQzCwWi9VqjYyM9D6BRDR8+PCPPvooJydn6NChBw4ciIuL++ijj7yvFiGEYOZxr0w3UlNTz58/n5KSUldXt3r16jVr1sgrXo95HsLjx497s2OAAPD+htCtkSNH5uXlZWVlRUREyMVQH3/8sce1eRjCv//97wsWLFizZo080gD0Tn4KIXXM/C4rK1u4cGF1dfUTTzzx4x//uLGx0YOqPAyh1WodNGhQbm6uVqvdt2+fZ5UA+Js/Lkedyce3ZWVlDRgwYPv27bGxsceOHVNbiYchXL9+fVlZWVJS0vXr11NSUhgXRAJ0w39nQgd5Sjxz5sycOXOqqqoWLVq0YcOG5uZm5TV4fk/ouiDy6NGjHtcG4A8BCKEUExNz4sSJl156SaPRbNu27eDBg8rf61XvaKcFkYsXLw78gkiAbsgQBuA5Ti0tLVlZWdu3b5fz2n7yk58of6+KENrt9lWrVu3YsaPT9k4LImfOnBnIBZF+df78+d27d3O3Ajwn7wn9eiZsbGx8/fXXJ02atGnTpitXrkyePJmIIiMjVVQhFMvNzZVvWbdu3a1bt1wLfPrpp3FxcdSxPrKtrU155b3QnTt3Hn74YSJKTU29efMmd3PAE0lJSUR0+PBhf1RusVhMJtPQoUNlLmbOnJmdnV1cXExE8fHxyutREUIhRHZ29qBBg6hjnMS1QHt7u9FoDA0NJaLY2Nj//ve/qurvVex2uxwIkp/3448/5m4RqKbVaomotLTUt9XW1tYajcbBgwfL+CUmJubl5dntdiHEv/71LyJKTk5WXpu6EAohvvzyy0cffVTuW6fT3b5927XMf/7zH3lSDg8PNxqNVqtV7V56j8rKyoULF1LHDXBDQwN3i0AFObfzq6++8lWFly9f1uv1AwYMcMTv4MGDzgV27txJRE899ZTyOlWHUHScImQ75DiJa5nm5maDwSAft5qQkHDx4kUPdtRL2Gw2s9nct29fIho/fvyxY8e4WwRK9evXj4iam5u9r6qyslKv18uvgUajSUlJOXXqlGuxN998k4h+9rOfKa/ZkxBK58+fnzNnjuMU0dTU5Frm4MGDo0ePpo71kTabzePdBUZTU9Nf//pXtwfO8vLy2bNny8+r1+tbW1sD3zxQpaGhgYgGDhzoZT1lZWU6nS4sLIyIQkJCUlJSzp4921XhjIwMIvrd736nvH7PQyiEuHPnjslk6tOnDxHFxMScOXPGtcw333yTlpYmz93JyclXrlzxZo/+09bW9txzzzn+0L/97W9dy8jPK+fjx8TEFBcXB76doFxVVRURjRkzxuMaSkpKUlNTNRoNEfXp00en0/V4Tbdp0yYiev3115XvxasQSqWlpTNnzuy+U3Tfvn2jRo2ijvWR3u/UhxoaGl599dWRI0fKI4X8ixPRs88+a7FYXMufPn166tSpQdMJHMTOnj1LRLNmzfLgvYWFhSkpKfKb0Ldv37S0NIXnj3Xr1hHRjh07lO/LByEUQrS0tBgMBtkpqtVqz50751qmtrb2ySeflJ/qscce+/rrr32ya2/ILmbHIJJWq33++edbW1vXrl0r73jHjBlz6NAh1zfKzyvveLVarc8738AnCgoKiGjJkiWq3lVYWLho0SL5lYiIiNDr9deuXVP+9mXLlhFRfn6+8rf4JoTSiRMnHnroISLq16+fyWRy2ykqF0RSx/pIH+5dFdnFHBUV5drFLF26dOn73/++4463sbHRtZLjx49PmjSp+88LjP72t78R0dq1a5UUttlseXl5cmSYiO677z6j0dj9+HBzc7Pzd0aSHQdub8264ssQCiGampr0er28ovve9773+eefu5aRc77lRw38OPj169cNBoNzF7PbAU8hhNVqNZlMsjdswoQJ//73v13LOH/e+fPnf/HFF35uPqjwxhtvEFF6enr3xWw2W05OTkxMjPxKREdHG43Gb775psf6f/WrX2k0mjfeeMN547hx44iosrJSeTt9HEKpoKDgwQcfJKIBAwaYzWbXowXLOLjsYpZ91rKL+eTJkz2+q6ysLD4+nohCQ0MNBoPbTtH8/PwHHnigm8/b27z66qsbN268dOkSd0P8y2g0EpF8nLZbbW1t2dnZ8vKNiMaOHWs2m5WPZ8gJou+9957zRjmbxe34eVf8EkLx3U7RpUuXXr161bVMwMbBy8vLlXcxu3KeBjRjxgy3762vr3d8XvlUPN8135fy8/Plt4SIoqKiuroKCA7p6elE9Kc//cn1pcbGRrPZLE8V8krHbDarHXaSF3TOf8O2tjYiCg8PV3Ug9lcIpdzcXDmBffDgwW47RZ3HwceNG+fzcfCSkhKdTifzEx4ertPpLly44FlVJ0+enDJliqzHYDC0t7e7lpG/hy6/372qE9hqte7cuVPO4ZJHoiFDhgTg8Mfr6aefJqIPP/zQeePt27fNZrPsqyei2NjY7Oxsz+7nExISiOjEiROOLdeuXSOiUaNGqarHvyEUQsifQZUf+Ec/+lFtba1rGedx8K7G/dWSXczybk1VF3M3nKcBzZs3z22eq6urf/CDH8jPu3r16rq6Oi936qX29vbs7Gw5pkJEI0aM2LJlS11dnZJpT/e6pUuXElFBQYH8Z11dndFolEcfIoqPj8/JyfHm3kFexzqPHH766afycklVPX4PoSR/H1ze9e7atcu1QKdxcFWdS50UFhYuXrzYuYvZt8MhhYWFEydOpG6nATl/3t27d/tw78rJGx7ZfyuTZjabW1panMsomfZ075o1axYRFRcXV1dXG41Gx/KibnrjVJH9/Ddu3HBskevaFy5cqKqeAIVQCCFX/XbfKerNOLjdbs/Ly5s7d67cRWRkpMFg8FPXq8VicdwBJiYm/u9//3MtI5904Pi8bhd/+UlDQ4PZbHY8l3b69OnZ2dl37txxW9h52tO0adNOnz4dsHb629ixY4nomWee6d+/v/xTJCcnO189esNqtYaEhISEhDgfhf/xj3/IKz5VVQUuhKKjU3TgwIHyuvmf//yna5nm5uZf/OIX8pLv5z//uZJqO3UxDx8+XGEXs5f2798vv+hdTQNy/rxdjfv7ltsVbkpueJRMe7q3VFRUOB74GxISsmbNmpKSEh/WX1dXR0TDhg1z3vj2228TUVpamqqqAhpCqdM4uNtegePHj8+ePbvHuzh5xSWXTckvuqouZu/V19evX79e7n358uVur3uVjPt7r8fpBz1ynvYUGxvr269sIJWWlsreOHko79+//1tvveXzvXz22WdENGXKFOeNf/zjH4noxRdfVFUVQwiFyzj4J598oraG1tbWrKwsL7uYfSUnJ0fOfYuKitq+fbtrAXnJ1/24v8dcV7h5c8OjZNpTr1VUVPTYY4/J3rh+/fqtW7dO3hZqNJr09HTf3vHKZ7jMnz/feeMvf/lLInrttddUVcUTQqmsrEz+jUJCQpQvDurUxTxjxoxubngC5vr1648//rjjDtD5Zt1Bybi/Kp5NP+hRc3Oz87Sne2ItqPN864EDB+r1erkerdNaUA8O913Zs2cPET3xxBPOG+Xw/fvvv6+qKs4QCiHa29sdnaLTp0/vfgz9xo0bzl3McXFxXnYx+5zj8R8jRozYu3evawEl4/5KqFrh5pkDBw7IaUARERH73n9f9Ka/s4PsjZPjdUQ0aNAgvV5//fr1TsXKy8s9ONx37y9/+QsRPfvss84bV65cSURqZ4Axh1DqcRy8pqbG9ZEeLE3tkZLHfygZ9++KnH4g73a8nH7QIzntKWrw4KujRoklS0RvmgYk51vL4WXZQWI0Guvr67sqr+pwr8TWrVuJ6IUXXnDe6Dp8r0SvCKH47jj43LlzHb0CVVVVer3e0cWcmJjopydn+VCncfAjR464lmlqakpPT9doNBqNRuH/mT+mHyjx1d69YvhwQSSGDBFqlsn5iev0A5PJpPB+79SpU85jYKoOf50YDAYieuWVV5w3ylFZt+sWutFbQig5xsE1Gs0jjzzy0EMPySs3ecV1bw1hVVRUKHn8xx/+8Iceq/L39IOe1dSIVasEkSASK1cKNevrfKi1tbXH6Qc96nS4/+yzzzxrzE9/+lMieuedd5w3ynsltaPTvSuEQgiLxeJY0yWtXr26oqKCu12e8HIcvNP0AyUr3PwrJ0cMHSqIRHS0cDftyY9u3xZbt762ZIn8U0yfPn3Hjh3e9MYVFRXJw73sBPbg6UdyMqbz9C85fB8aGqq2tl4XQikjIyM6OnrKlClur+XuLaWlpWqfiezxCje/u3ZNrFx595SYmioCcESwWITJJMPfNHXqw3Pm7Nq1yydPDOs07UntWlA59us82lRbW0suw/dK9NIQBhnl4+Ds0w96ZreLrCwRESGIxKhRwt20J9+orRVGo4iKupv5xESRl+fzTlpHJ7Cc9qS8s33atGlEdP78eccWt8P3SiCEgdP9OHivmn7Qs8pK8cgjgkhoNCItTfh2MdTly0KvFwMGfCd+ftNp2pPCJwVHR0cTUXV1tWNLYWGhPKmqbQBCGFDO4+Dz5s2TD2+urq721Qq3gLLZhNks+vYVRGL8eOGTcfDKSqHXi3797sY7JUX4YvqBEs7Tnj744IPuC9vt9rCwMI1G49y/6nb4XgmEkIHjcRgajWbMmDGOhyzOmzdP7YRPfuXlYtYsQSRCQoReLzw+dZeVCZ1OhIXdrSolRfh6+kGP5K9ey/+LrqY9SfIncQcPHuy80e3wvRIIIY/6+nrHo02I6MEHH+y10w961tYmXnrpbn5iY78dwGhpEW++KZYtE1OnimnTxPLl4q23hGu/VEmJSE0VGo0gEuHhQqcTfpt+oESP056EEO3t7YWFhY7lwlJmZiYR/frXv1a7R4SQk9FoXLRo0dtvv83dEF84dUpMnSrmzxfyQvqrr0RMjCASDz8sNm0S6ekiPl4QCa3225QWFoqUlLs3fn37irQ00Tse0F5VVSV/U62baU+ufvOb3xCRyWRSuzuEEHynufluwOx2kZgoQkM7z7DJyhIajUhKEkIIi0VERgoiERkpNm8WNTUMDe6a81rQsWPHKhkqczt8rwRCCH5QUCCIxMaNbl5av14QCflEL5NJ/P73IoDPHFCroqJCTh1RshbUdfheIa9+sx7Avf37iYieftrNS888820Bg4G2bKGOZTG90LRp006cOKHwp+DlT3PLx+2pghCCH1y4QEQ0frybl2Jjvy1wL5DznIqLi+Pi4i5dupSUlLR58+b29nbXkjdv3iQix0+bKIcQgh80NhIRjRjh5iX5yLOGhoC2x2uxsbGnT5+WD/POzMycM2fOuXPnOpVBCKE3iYggIqqtdfOSjF/H0wfvIeHh4RkZGUVFRZMnTy4rK5s7d25GRobNZpOvCiFu3bql0WgcT9lSDiEEP5BDoJcvu3mpooKIaMqUgLbHdxISEs6dO2cwGGw228svv7xgwYLPP/+ciCwWi9VqjYyMdDziTTmEEPxg2TIiol273Ly0c+e3Be5N8qHP+fn5o0ePPnnyZFxcXGZmpmMJhSc1etp5C9A1q1XMnCn69hWdhtf27xdhYSIhoXc+sUYt5189kst5o6KiPKhHI4Tw3TECoMOFC5ScTNXV9OSTlJhIQlBhIe3ZQ2PG0OHDNGECd/t8Zvfu3TqdrqmpiYiGDRsmHwqsCkIIflNXR1u3Ul4eVVUREU2YQKtW0QsvkPqui16uoqJi8eLF1dXVy5cvP3DggNq3I4QAvpGTk3Px4sUtW7aofSNCCOAzQgjHwjTl0DsK4DMeJJAQQgB2CCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzBBCAGYIIQAzhBCAGUIIwAwhBGCGEAIwQwgBmCGEAMwQQgBmCCEAM4QQgBlCCMAMIQRghhACMEMIAZghhADMEEIAZgghADOEEIAZQgjADCEEYIYQAjBDCAGYIYQAzP4P6UNUgCaVwV0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Mol Viz\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "input_ids = tokenizer(\"<s>\", return_tensors=\"pt\").input_ids.to(device)\n",
    "gen = model.generate(input_ids, max_length=25, top_k=50, temperature=1, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
    "generatedmol = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
    "\n",
    "test = generatedmol.replace(' ', '')\n",
    "csmi_gen = sf.decoder(test)\n",
    "print(csmi_gen)\n",
    "mol = Chem.MolFromSmiles(csmi_gen)\n",
    "\n",
    "# Draw the molecule\n",
    "Draw.MolToImage(mol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
